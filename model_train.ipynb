{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "__bqIbeRFofW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v5GshKzMDyH",
        "outputId": "2f2a6861-a445-4e9f-f90f-be80821ed742"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\smart\\Anaconda3\\envs\\workspace\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (16,17,18,22,23,24,25,26,27,28,29,30,31,32,33,76) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ],
      "source": [
        "all_data=pd.read_csv(\"dataset.data\",nrows=25175)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "K_Z6quqsMJ5L",
        "outputId": "8d11dd0d-3a1d-42ff-b5b5-89a9c34ccc3d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>m_id</th>\n",
              "      <th>client_m_id</th>\n",
              "      <th>hl_id</th>\n",
              "      <th>house_no</th>\n",
              "      <th>house_hold_no</th>\n",
              "      <th>state</th>\n",
              "      <th>district</th>\n",
              "      <th>rural</th>\n",
              "      <th>stratum_code</th>\n",
              "      <th>...</th>\n",
              "      <th>householdstatus</th>\n",
              "      <th>isheadchanged</th>\n",
              "      <th>fidh</th>\n",
              "      <th>fidx</th>\n",
              "      <th>as</th>\n",
              "      <th>wt</th>\n",
              "      <th>x</th>\n",
              "      <th>schedule_id</th>\n",
              "      <th>year</th>\n",
              "      <th>v126</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>712232</td>\n",
              "      <td>375.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2944.0</td>\n",
              "      <td>63</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.944096e+10</td>\n",
              "      <td>-0.630351</td>\n",
              "      <td>68.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>712240</td>\n",
              "      <td>383.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2997.0</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.997096e+10</td>\n",
              "      <td>-4.369212</td>\n",
              "      <td>68.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>109886</td>\n",
              "      <td>246.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.620340e+13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>712216</td>\n",
              "      <td>359.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2706.0</td>\n",
              "      <td>196</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.706096e+10</td>\n",
              "      <td>-2.996541</td>\n",
              "      <td>68.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>712224</td>\n",
              "      <td>367.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2777.0</td>\n",
              "      <td>253</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.777096e+10</td>\n",
              "      <td>-3.951137</td>\n",
              "      <td>68.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25170</th>\n",
              "      <td>643135</td>\n",
              "      <td>410.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>6366.0</td>\n",
              "      <td>244</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.366090e+10</td>\n",
              "      <td>5.052841</td>\n",
              "      <td>54.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25171</th>\n",
              "      <td>643143</td>\n",
              "      <td>938.0</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>6483.0</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.483090e+10</td>\n",
              "      <td>0.292205</td>\n",
              "      <td>54.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25172</th>\n",
              "      <td>102148</td>\n",
              "      <td>38.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.610740e+13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25173</th>\n",
              "      <td>643119</td>\n",
              "      <td>394.0</td>\n",
              "      <td>385.0</td>\n",
              "      <td>6140.0</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.140090e+10</td>\n",
              "      <td>-2.376460</td>\n",
              "      <td>54.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25174</th>\n",
              "      <td>643127</td>\n",
              "      <td>402.0</td>\n",
              "      <td>393.0</td>\n",
              "      <td>6229.0</td>\n",
              "      <td>122</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.229090e+10</td>\n",
              "      <td>-0.566020</td>\n",
              "      <td>54.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25175 rows × 122 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id   m_id  client_m_id   hl_id  house_no  house_hold_no  state  \\\n",
              "0      712232  375.0          NaN  2944.0        63              3      9   \n",
              "1      712240  383.0          NaN  2997.0        28              1      9   \n",
              "2      109886  246.0          NaN     NaN        58              1      9   \n",
              "3      712216  359.0          NaN  2706.0       196              1      9   \n",
              "4      712224  367.0          NaN  2777.0       253              1      9   \n",
              "...       ...    ...          ...     ...       ...            ...    ...   \n",
              "25170  643135  410.0        401.0  6366.0       244              1      9   \n",
              "25171  643143  938.0       1009.0  6483.0        66              1      9   \n",
              "25172  102148   38.0          NaN     NaN        56              1      9   \n",
              "25173  643119  394.0        385.0  6140.0        34              1      9   \n",
              "25174  643127  402.0        393.0  6229.0       122              1      9   \n",
              "\n",
              "       district  rural  stratum_code  ...  householdstatus  isheadchanged  \\\n",
              "0            58      1             1  ...              NaN            NaN   \n",
              "1            58      1             1  ...              NaN            NaN   \n",
              "2            62      1             2  ...              1.0            1.0   \n",
              "3            58      1             1  ...              NaN            NaN   \n",
              "4            58      1             1  ...              NaN            NaN   \n",
              "...         ...    ...           ...  ...              ...            ...   \n",
              "25170         3      1             2  ...              NaN            NaN   \n",
              "25171         3      1             2  ...              NaN            NaN   \n",
              "25172        61      2             0  ...              1.0            2.0   \n",
              "25173         3      1             2  ...              NaN            NaN   \n",
              "25174         3      1             2  ...              NaN            NaN   \n",
              "\n",
              "               fidh          fidx        as     wt   x schedule_id year  v126  \n",
              "0               NaN  2.944096e+10 -0.630351  68.37 NaN           4    1   NaN  \n",
              "1               NaN  2.997096e+10 -4.369212  68.37 NaN           4    1   NaN  \n",
              "2      9.620340e+13           NaN       NaN  20.95 NaN           4    3   NaN  \n",
              "3               NaN  2.706096e+10 -2.996541  68.37 NaN           4    1   NaN  \n",
              "4               NaN  2.777096e+10 -3.951137  68.37 NaN           4    1   NaN  \n",
              "...             ...           ...       ...    ...  ..         ...  ...   ...  \n",
              "25170           NaN  6.366090e+10  5.052841  54.85 NaN           4    1   NaN  \n",
              "25171           NaN  6.483090e+10  0.292205  54.85 NaN           4    1   NaN  \n",
              "25172  9.610740e+13           NaN       NaN  54.00 NaN           4    3   NaN  \n",
              "25173           NaN  6.140090e+10 -2.376460  54.85 NaN           4    1   NaN  \n",
              "25174           NaN  6.229090e+10 -0.566020  54.85 NaN           4    1   NaN  \n",
              "\n",
              "[25175 rows x 122 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2dRz699vY0bf"
      },
      "outputs": [],
      "source": [
        "columns = [\"age\",\"sex\", \"highest_qualification\", \"rural\", \"disability_status\", \"is_water_filter\", \"chew\", \"smoke\", \"alcohol\",\"treatment_source\"]\n",
        "death = all_data[columns].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gc4_n89QpesQ"
      },
      "outputs": [],
      "source": [
        "for column in columns:\n",
        "    death[column].fillna(death[column].mode()[0], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIKBYuxLpiqo",
        "outputId": "93155224-9637-4469-ee37-e2954e39c92e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age                      0\n",
              "sex                      0\n",
              "highest_qualification    0\n",
              "rural                    0\n",
              "disability_status        0\n",
              "is_water_filter          0\n",
              "chew                     0\n",
              "smoke                    0\n",
              "alcohol                  0\n",
              "treatment_source         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "death.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "CnpmYoLlGclT",
        "outputId": "a693a44f-c2c1-44bd-cbf0-0828cf3fd29d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>highest_qualification</th>\n",
              "      <th>rural</th>\n",
              "      <th>disability_status</th>\n",
              "      <th>is_water_filter</th>\n",
              "      <th>chew</th>\n",
              "      <th>smoke</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>treatment_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>70.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25170</th>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25171</th>\n",
              "      <td>38.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25172</th>\n",
              "      <td>42.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25173</th>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25174</th>\n",
              "      <td>60.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25175 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        age  sex  highest_qualification  rural  disability_status  \\\n",
              "0      43.0  1.0                    4.0      1                0.0   \n",
              "1      70.0  2.0                    0.0      1                0.0   \n",
              "2      57.0  2.0                    3.0      1                0.0   \n",
              "3      50.0  1.0                    0.0      1                0.0   \n",
              "4      65.0  2.0                    0.0      1                0.0   \n",
              "...     ...  ...                    ...    ...                ...   \n",
              "25170  38.0  1.0                    4.0      1                0.0   \n",
              "25171  38.0  2.0                    0.0      1                0.0   \n",
              "25172  42.0  1.0                    0.0      2                0.0   \n",
              "25173  35.0  1.0                    0.0      1                0.0   \n",
              "25174  60.0  2.0                    0.0      1                0.0   \n",
              "\n",
              "       is_water_filter  chew  smoke  alcohol  treatment_source  \n",
              "0                  2.0   7.0    4.0      4.0               0.0  \n",
              "1                  2.0   5.0    4.0      4.0               9.0  \n",
              "2                  2.0   7.0    4.0      4.0               0.0  \n",
              "3                  2.0   1.0    1.0      1.0               9.0  \n",
              "4                  2.0   7.0    4.0      4.0               0.0  \n",
              "...                ...   ...    ...      ...               ...  \n",
              "25170              2.0   3.0    4.0      4.0               9.0  \n",
              "25171              2.0   7.0    4.0      4.0               8.0  \n",
              "25172              2.0   1.0    1.0      4.0               6.0  \n",
              "25173              2.0   7.0    1.0      4.0               8.0  \n",
              "25174              2.0   7.0    4.0      4.0               8.0  \n",
              "\n",
              "[25175 rows x 10 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "death"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KF8cBrpFtKG",
        "outputId": "4f84779a-a034-4ab7-839b-5023e5ca5a05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age                      float64\n",
              "sex                      float64\n",
              "highest_qualification    float64\n",
              "rural                      int64\n",
              "disability_status        float64\n",
              "is_water_filter          float64\n",
              "chew                     float64\n",
              "smoke                    float64\n",
              "alcohol                  float64\n",
              "treatment_source         float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "death.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JWoVMu4kq_0k"
      },
      "outputs": [],
      "source": [
        "x=death.drop('age',axis=1)\n",
        "y=death['age']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTBjdWv1rHKD",
        "outputId": "0d63eac2-55ab-4743-f20c-e33c2edd16bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25175, 9)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guIUGSszFwJt",
        "outputId": "782f8e98-c5af-4025-ff35-24f53d28e28a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sex                      float64\n",
              "highest_qualification    float64\n",
              "rural                      int64\n",
              "disability_status        float64\n",
              "is_water_filter          float64\n",
              "chew                     float64\n",
              "smoke                    float64\n",
              "alcohol                  float64\n",
              "treatment_source         float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbDv1mqYrItn",
        "outputId": "7078b7ea-4bce-496f-9595-f03074b629c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25175,)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "luOCyZesrTTW"
      },
      "outputs": [],
      "source": [
        "#train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(x,y ,random_state=104,test_size=0.25,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1U0H5Aqs6MW",
        "outputId": "171443b8-41de-4a90-d5d8-9e1c9df9ffc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18881, 9)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.937781159786292\n",
            "203.60133116755716\n",
            "0.04146390900500163\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "print(mean_absolute_error(y_test,y_pred))\n",
        "print(mean_squared_error(y_test,y_pred))\n",
        "print(r2_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x1ca15764208>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 3.84 %\n",
            "Standard Deviation: 0.82 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "cvs = cross_val_score(reg,X_train,y_train,cv=10,n_jobs=-1)\n",
        "print('Accuracy: {:.2f} %'.format(cvs.mean()*100))\n",
        "print('Standard Deviation: {:.2f} %'.format(cvs.std()*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestRegressor()"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Train the model on the training data\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): 205.11732706512902\n",
            "R-squared (R2) Score: 0.034326741613757705\n"
          ]
        }
      ],
      "source": [
        "y_pred = rf.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R2) Score:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=1, activation='linear'))  # Use linear activation for regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKsDJYLus_Ve",
        "outputId": "5b6acb09-3cc4-42c7-aabd-c07c3f60624d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 64)                640       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,753\n",
            "Trainable params: 2,753\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "BHERl9jsuHoB"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),loss=tf.keras.losses.MeanSquaredError(),metrics=[tf.keras.metrics.RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define callback functions\n",
        "checkpoint = ModelCheckpoint('best_model.{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "def scheduler(epoch, lr):\n",
        "    # Define learning rate scheduler function\n",
        "    if epoch < 50:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * 0.1\n",
        "lr_scheduler = LearningRateScheduler(scheduler, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71Wo-Psxvqju",
        "outputId": "ca262a6b-1b88-4c60-9b3a-24f3135af71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 1/100\n",
            "587/591 [============================>.] - ETA: 0s - loss: 287.4823 - root_mean_squared_error: 16.9553\n",
            "Epoch 00001: val_loss improved from inf to 206.39902, saving model to best_model.01-206.40.h5\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 287.1456 - root_mean_squared_error: 16.9454 - val_loss: 206.3990 - val_root_mean_squared_error: 14.3666\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 2/100\n",
            "590/591 [============================>.] - ETA: 0s - loss: 222.3145 - root_mean_squared_error: 14.9102\n",
            "Epoch 00002: val_loss did not improve from 206.39902\n",
            "591/591 [==============================] - 2s 4ms/step - loss: 222.3064 - root_mean_squared_error: 14.9099 - val_loss: 209.4920 - val_root_mean_squared_error: 14.4738\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 3/100\n",
            "582/591 [============================>.] - ETA: 0s - loss: 221.8415 - root_mean_squared_error: 14.8943\n",
            "Epoch 00003: val_loss did not improve from 206.39902\n",
            "591/591 [==============================] - 2s 4ms/step - loss: 222.3658 - root_mean_squared_error: 14.9119 - val_loss: 282.0820 - val_root_mean_squared_error: 16.7953\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 4/100\n",
            "586/591 [============================>.] - ETA: 0s - loss: 216.7386 - root_mean_squared_error: 14.7220\n",
            "Epoch 00004: val_loss improved from 206.39902 to 204.40489, saving model to best_model.04-204.40.h5\n",
            "591/591 [==============================] - 2s 4ms/step - loss: 216.6965 - root_mean_squared_error: 14.7206 - val_loss: 204.4049 - val_root_mean_squared_error: 14.2970\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 5/100\n",
            "591/591 [==============================] - ETA: 0s - loss: 212.1381 - root_mean_squared_error: 14.5650\n",
            "Epoch 00005: val_loss improved from 204.40489 to 204.29115, saving model to best_model.05-204.29.h5\n",
            "591/591 [==============================] - 2s 4ms/step - loss: 212.1381 - root_mean_squared_error: 14.5650 - val_loss: 204.2912 - val_root_mean_squared_error: 14.2930\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 6/100\n",
            "576/591 [============================>.] - ETA: 0s - loss: 214.3156 - root_mean_squared_error: 14.6395\n",
            "Epoch 00006: val_loss improved from 204.29115 to 203.51299, saving model to best_model.06-203.51.h5\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 213.6121 - root_mean_squared_error: 14.6155 - val_loss: 203.5130 - val_root_mean_squared_error: 14.2658\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 7/100\n",
            "579/591 [============================>.] - ETA: 0s - loss: 213.4377 - root_mean_squared_error: 14.6095\n",
            "Epoch 00007: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 213.5987 - root_mean_squared_error: 14.6150 - val_loss: 213.6534 - val_root_mean_squared_error: 14.6169\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 8/100\n",
            "588/591 [============================>.] - ETA: 0s - loss: 213.9785 - root_mean_squared_error: 14.6280\n",
            "Epoch 00008: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 213.9409 - root_mean_squared_error: 14.6267 - val_loss: 208.9706 - val_root_mean_squared_error: 14.4558\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 9/100\n",
            "585/591 [============================>.] - ETA: 0s - loss: 213.7786 - root_mean_squared_error: 14.6212\n",
            "Epoch 00009: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 213.8797 - root_mean_squared_error: 14.6246 - val_loss: 210.9626 - val_root_mean_squared_error: 14.5246\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 10/100\n",
            "590/591 [============================>.] - ETA: 0s - loss: 215.2250 - root_mean_squared_error: 14.6705\n",
            "Epoch 00010: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 215.2377 - root_mean_squared_error: 14.6710 - val_loss: 221.4000 - val_root_mean_squared_error: 14.8795\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 11/100\n",
            "574/591 [============================>.] - ETA: 0s - loss: 215.6881 - root_mean_squared_error: 14.6863\n",
            "Epoch 00011: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 215.3662 - root_mean_squared_error: 14.6754 - val_loss: 204.3954 - val_root_mean_squared_error: 14.2967\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 12/100\n",
            "585/591 [============================>.] - ETA: 0s - loss: 212.9194 - root_mean_squared_error: 14.5918\n",
            "Epoch 00012: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 212.8716 - root_mean_squared_error: 14.5901 - val_loss: 217.6158 - val_root_mean_squared_error: 14.7518\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 13/100\n",
            "572/591 [============================>.] - ETA: 0s - loss: 220.6573 - root_mean_squared_error: 14.8545\n",
            "Epoch 00013: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 220.8907 - root_mean_squared_error: 14.8624 - val_loss: 216.3387 - val_root_mean_squared_error: 14.7085\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 14/100\n",
            "575/591 [============================>.] - ETA: 0s - loss: 220.2620 - root_mean_squared_error: 14.8412\n",
            "Epoch 00014: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 220.1451 - root_mean_squared_error: 14.8373 - val_loss: 213.9313 - val_root_mean_squared_error: 14.6264\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 15/100\n",
            "588/591 [============================>.] - ETA: 0s - loss: 220.0410 - root_mean_squared_error: 14.8338\n",
            "Epoch 00015: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 219.9914 - root_mean_squared_error: 14.8321 - val_loss: 218.3748 - val_root_mean_squared_error: 14.7775\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.10000000149011612.\n",
            "Epoch 16/100\n",
            "578/591 [============================>.] - ETA: 0s - loss: 220.4808 - root_mean_squared_error: 14.8486\n",
            "Epoch 00016: val_loss did not improve from 203.51299\n",
            "591/591 [==============================] - 2s 3ms/step - loss: 220.1309 - root_mean_squared_error: 14.8368 - val_loss: 212.9460 - val_root_mean_squared_error: 14.5927\n",
            "Epoch 00016: early stopping\n"
          ]
        }
      ],
      "source": [
        "learning = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=True,\n",
        "                    validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping, lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 212.9460\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Print the mean squared error\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "QLLtn7gEyNIE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "hcyJPqaAwmXP"
      },
      "outputs": [],
      "source": [
        "def plot(learning):\n",
        "  plt.plot(learning.history['loss'])\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(\"Cost\")\n",
        "\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "qXR14ENhyfIE",
        "outputId": "e3d3d94e-db7a-4469-a374-b57593c14997"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot(learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX9x_DITjcsx",
        "outputId": "e79df952-a11f-4b22-fbc5-dcbc34aef2b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_3/kernel:0' shape=(9, 64) dtype=float32, numpy=\n",
              " array([[-6.96983486e-02, -4.66652006e-01,  2.50819087e-01,\n",
              "         -4.03178632e-01, -2.01007053e-01, -5.44434309e-01,\n",
              "         -8.10218513e-01, -4.15979028e-01, -5.64948142e-01,\n",
              "         -5.80097139e-01, -8.81188810e-01,  1.84626937e-01,\n",
              "         -3.67763191e-01, -2.19940126e-01, -2.55165637e-01,\n",
              "         -7.64534354e-01,  1.19019084e-01, -1.98470503e-01,\n",
              "         -3.66578281e-01, -5.65478802e-01, -8.19266737e-01,\n",
              "         -1.79027900e-01, -6.44648969e-01, -8.60403657e-01,\n",
              "         -5.05969226e-01, -2.06630766e-01, -7.18178213e-01,\n",
              "         -8.81597042e-01, -3.73193860e-01, -9.88935947e-01,\n",
              "         -5.78256071e-01, -6.08838916e-01, -3.82609338e-01,\n",
              "         -5.34768462e-01, -7.16523170e-01, -7.19237387e-01,\n",
              "         -7.58819759e-01, -4.29701596e-01, -6.58414885e-02,\n",
              "         -2.07177121e-02, -4.19760376e-01, -7.55376577e-01,\n",
              "         -4.77958381e-01, -1.61530957e-01, -2.24095643e-01,\n",
              "         -5.77447951e-01, -1.67566612e-01, -5.93755618e-02,\n",
              "         -1.23214507e+00, -7.88553238e-01, -7.57875741e-01,\n",
              "         -6.06311619e-01, -1.48182273e+00, -2.90978837e+00,\n",
              "         -4.51565683e-01, -3.49329859e-02, -6.58448696e-01,\n",
              "         -3.83788049e-01, -9.52116847e-02, -3.68739694e-01,\n",
              "         -7.34643579e-01,  8.60094056e-02, -4.99294847e-01,\n",
              "         -3.26561761e+00],\n",
              "        [-8.48363817e-01, -4.27402198e-01, -2.53309220e-01,\n",
              "         -7.41140544e-01, -5.91233261e-02, -7.85942793e-01,\n",
              "         -1.61140990e+00, -1.88170895e-01, -5.26693702e-01,\n",
              "         -4.61410493e-01, -4.22630310e-01, -6.34572554e+00,\n",
              "          3.57482135e-02, -5.39431036e-01, -2.62180179e-01,\n",
              "         -4.01415616e-01, -8.55642557e-02, -4.80297893e-01,\n",
              "         -2.55756587e-01, -1.19896829e+00, -7.78501034e-01,\n",
              "         -4.19610292e-01, -4.46924984e-01, -4.13029939e-01,\n",
              "         -5.55936456e-01, -8.91140103e-01, -5.81810951e-01,\n",
              "         -2.72814363e-01, -4.82585073e-01, -7.58591145e-02,\n",
              "         -4.01977748e-01, -4.78785068e-01, -2.59180248e-01,\n",
              "         -2.96231031e-01, -7.41430700e-01, -3.68374228e-01,\n",
              "         -5.75402975e-01, -5.51842928e-01, -3.49659264e-01,\n",
              "         -3.58117342e-01, -4.04801548e-01, -4.97591048e-01,\n",
              "         -8.47350240e-01, -5.84234357e-01, -6.50650918e-01,\n",
              "         -2.57156342e-01, -4.17977065e-01, -4.55917627e-01,\n",
              "         -1.25789747e-01, -2.62992501e-01, -4.36103433e-01,\n",
              "         -7.55937934e-01, -7.43228674e-01, -1.79005659e+00,\n",
              "          4.20020372e-02, -4.18857843e-01, -5.33133447e-01,\n",
              "         -8.33610356e-01, -3.71581167e-01, -1.68640345e-01,\n",
              "         -8.14486682e-01, -4.62006569e+00, -8.84976268e-01,\n",
              "          5.20457745e-01],\n",
              "        [-3.40194046e-01, -2.62667447e-01, -8.71400908e-02,\n",
              "         -2.51952231e-01,  9.21548232e-02, -4.98824678e-02,\n",
              "         -7.09118426e-01, -4.42042559e-01, -6.31250679e-01,\n",
              "         -1.62949279e-01, -5.95562041e-01, -2.57279545e-01,\n",
              "         -7.61236429e-01, -3.83859068e-01, -2.78545201e-01,\n",
              "         -7.87972808e-01, -5.57683001e-04, -3.71987879e-01,\n",
              "         -4.45171475e-01, -3.60801309e-01, -4.86501545e-01,\n",
              "         -2.98962921e-01, -2.41939172e-01, -3.54025543e-01,\n",
              "         -6.77873790e-01, -5.39210916e-01, -5.11150897e-01,\n",
              "         -5.00512719e-01,  1.12627158e-02, -1.17459260e-01,\n",
              "         -7.96049476e-01, -5.20902038e-01, -5.13105094e-01,\n",
              "         -3.70024055e-01, -8.01725030e-01, -8.22579503e-01,\n",
              "         -3.76982808e-01, -3.98949921e-01, -4.88657027e-01,\n",
              "          2.29715705e-02, -1.85186088e-01, -7.82442689e-01,\n",
              "         -2.17295364e-01, -2.33793840e-01, -4.98662084e-01,\n",
              "         -1.63854510e-01, -4.64554638e-01, -1.56022102e-01,\n",
              "         -3.95931989e-01, -3.95060986e-01, -3.39662552e-01,\n",
              "         -6.24280751e-01, -8.28597546e-01, -3.79871488e-01,\n",
              "         -3.59246194e-01, -1.55572429e-01, -3.83968890e-01,\n",
              "         -3.44236612e-01,  9.48886294e-03, -3.22571069e-01,\n",
              "         -8.76477599e-01, -3.65812182e+00, -7.56693661e-01,\n",
              "         -7.49151647e-01],\n",
              "        [ 1.15476668e-01, -1.46943167e-01, -1.81647968e+00,\n",
              "         -4.60468084e-02, -4.09484178e-01, -3.56386572e-01,\n",
              "         -4.06547248e-01, -1.37684450e-01, -4.66470659e-01,\n",
              "         -6.62198141e-02, -5.10983288e-01, -8.04486349e-02,\n",
              "         -8.50421041e-02, -5.82677573e-02,  3.74216735e-02,\n",
              "         -6.63888931e-01, -1.40906991e-02,  7.07725883e-02,\n",
              "         -1.69053867e-01, -3.66699308e-01, -3.62517983e-01,\n",
              "         -1.92663640e-01,  3.35638821e-02, -3.80523592e-01,\n",
              "         -8.38835835e-01,  7.99494982e-02, -5.10559618e-01,\n",
              "         -8.23722035e-02,  1.53301312e-02, -5.48992455e-01,\n",
              "         -6.48574948e-01, -5.27260125e-01,  2.66801208e-01,\n",
              "          6.67669773e-02, -6.00304306e-01, -5.33197582e-01,\n",
              "         -4.78152037e-01, -6.59168184e-01, -4.28546935e-01,\n",
              "         -1.79610103e-01, -9.18631405e-02, -1.28648534e-01,\n",
              "         -4.74921316e-02,  1.10408753e-01, -2.34370217e-01,\n",
              "         -4.37839061e-01, -5.95934270e-03, -4.60488617e-01,\n",
              "         -6.75806880e-01, -1.44120604e-02,  1.22480996e-01,\n",
              "         -1.39610767e-01, -5.36157846e-01, -5.09153247e-01,\n",
              "          6.00622483e-02, -2.70024925e-01, -2.62871683e-01,\n",
              "         -4.00809795e-01, -2.19719619e-01, -5.11297137e-02,\n",
              "          7.96719372e-01, -2.55706072e-01, -2.20606074e-01,\n",
              "         -2.11768103e+00],\n",
              "        [-1.70453250e-01, -4.51027036e-01, -1.06457822e-01,\n",
              "         -6.16877675e-01, -6.90046176e-02, -6.83691949e-02,\n",
              "          4.84175265e-01, -4.28618163e-01, -7.79434919e-01,\n",
              "          1.13197438e-01,  4.27814513e-01, -4.76225042e+00,\n",
              "         -8.72182131e-01, -2.52559483e-01, -2.10550740e-01,\n",
              "         -4.58981007e-01, -1.37404472e-01, -2.59266980e-02,\n",
              "         -4.57975894e-01,  3.25904965e-01, -7.04095423e-01,\n",
              "         -4.04904813e-01, -6.74610257e-01, -5.52104890e-01,\n",
              "         -6.32541418e-01, -6.52384162e-02, -7.10385203e-01,\n",
              "         -4.51953471e-01, -2.13385075e-01,  3.31731111e-01,\n",
              "         -6.50263131e-01, -6.40297830e-01, -5.24685740e-01,\n",
              "         -3.15226376e-01, -5.78792751e-01, -7.04287887e-01,\n",
              "         -6.29752457e-01, -8.13961744e-01, -2.41873309e-01,\n",
              "         -1.14305831e-01, -1.21450610e-01, -8.74583840e-01,\n",
              "         -1.17464019e-02, -2.97047526e-01, -7.30302632e-01,\n",
              "          1.04577787e-01, -3.54796313e-02,  9.17640477e-02,\n",
              "          3.94559860e-01, -7.90883303e-01, -2.36010462e-01,\n",
              "         -3.48662317e-01,  2.40514517e-01, -1.74884275e-01,\n",
              "         -1.52414411e-01, -3.43214333e-01, -5.36649644e-01,\n",
              "         -5.57875812e-01, -1.15169980e-01, -3.87094349e-01,\n",
              "         -1.38241303e+00, -1.07867396e+00, -4.76866573e-01,\n",
              "         -1.26819462e-01],\n",
              "        [-2.56077260e-01, -5.87836325e-01, -1.73537359e-01,\n",
              "         -6.96882367e-01, -2.96375970e-03, -4.86572593e-01,\n",
              "         -5.56760252e-01, -5.84520757e-01, -4.71572995e-01,\n",
              "         -4.63240266e-01, -3.03757995e-01, -1.05925608e+00,\n",
              "         -7.83149004e-01, -1.70187250e-01,  1.15667522e-01,\n",
              "         -5.48923731e-01, -2.49148369e-01,  3.45650055e-02,\n",
              "         -6.60079002e-01, -3.38383526e-01, -3.13278973e-01,\n",
              "         -2.26619601e-01, -1.04893103e-01, -6.60675406e-01,\n",
              "         -4.62375343e-01, -2.41215721e-01, -6.60184920e-01,\n",
              "         -7.71575689e-01, -4.58650053e-01, -2.97701418e-01,\n",
              "         -7.56983638e-01, -4.93512779e-01, -6.81005180e-01,\n",
              "         -6.24093533e-01, -4.38812762e-01, -7.62422383e-01,\n",
              "         -3.22016716e-01, -3.27726305e-01, -2.97154635e-01,\n",
              "         -3.24984223e-01, -3.45260561e-01, -6.41565263e-01,\n",
              "         -2.39603177e-01, -1.09373040e-01, -5.93208194e-01,\n",
              "          1.33373903e-03, -4.45228577e-01, -4.22187150e-01,\n",
              "         -7.72190928e-01, -7.11113453e-01, -7.50905216e-01,\n",
              "         -4.91963804e-01, -8.05153012e-01, -1.32266080e+00,\n",
              "         -2.98171312e-01, -3.93327028e-01, -6.56219661e-01,\n",
              "         -7.53975511e-01, -8.94043371e-02, -7.24740088e-01,\n",
              "         -1.68336499e+00, -3.00040221e+00, -3.47145259e-01,\n",
              "         -1.55108583e+00],\n",
              "        [-2.40069315e-01, -2.39320174e-01, -1.15334652e-01,\n",
              "         -4.23905671e-01, -1.00659437e-01, -5.57648242e-01,\n",
              "         -6.92074358e-01, -4.37344611e-01, -6.17334247e-01,\n",
              "         -5.87941587e-01, -7.20993161e-01, -1.70948946e+00,\n",
              "         -7.94597685e-01, -3.17193687e-01, -9.39822793e-02,\n",
              "         -4.88708138e-01, -4.09954339e-02, -3.10916156e-01,\n",
              "         -2.74380505e-01, -2.21861944e-01, -8.79074156e-01,\n",
              "         -6.05239391e-01,  4.25502360e-02, -5.16268492e-01,\n",
              "         -3.52905691e-01, -2.57503480e-01, -8.53615642e-01,\n",
              "         -2.21839666e-01, -2.04941556e-01, -8.38183761e-01,\n",
              "         -8.73720825e-01, -6.64625764e-01, -4.41462457e-01,\n",
              "         -5.54672837e-01, -3.43988299e-01, -7.13115513e-01,\n",
              "         -7.26235032e-01, -3.15520525e-01, -1.90946475e-01,\n",
              "         -2.30491564e-01, -4.15409394e-02, -4.72872406e-01,\n",
              "         -4.49657977e-01, -5.28663099e-01, -5.12617290e-01,\n",
              "         -7.63329029e-01, -3.20847094e-01,  4.67122085e-02,\n",
              "         -9.62498724e-01, -6.96428418e-01, -4.54549611e-01,\n",
              "         -4.87786502e-01, -1.31369376e+00, -2.00756264e+00,\n",
              "         -3.44815969e-01, -1.57277405e-01, -3.55392814e-01,\n",
              "         -7.95368850e-01, -2.19846562e-01, -8.42988372e-01,\n",
              "         -2.02094746e+00, -3.43493372e-01, -7.25964725e-01,\n",
              "         -1.43611515e+00],\n",
              "        [-4.67632473e-01, -1.46675944e-01, -6.28226623e-02,\n",
              "         -4.19697523e-01, -3.95680755e-01, -1.73383635e-02,\n",
              "          1.44579396e-01, -5.55050850e-01, -4.84220177e-01,\n",
              "         -3.72125983e-01, -1.07416280e-01,  1.79469585e+00,\n",
              "         -7.34129727e-01, -3.29368293e-01, -1.32488161e-01,\n",
              "         -5.49822688e-01,  4.59791385e-02,  9.36216712e-02,\n",
              "         -2.56053984e-01, -3.55750978e-01, -5.15374541e-01,\n",
              "         -5.12944400e-01, -1.78438336e-01, -3.64723742e-01,\n",
              "         -5.27900755e-01, -3.53154659e-01, -6.76557958e-01,\n",
              "         -6.91354632e-01, -3.09668869e-01, -6.64532304e-01,\n",
              "         -3.54658484e-01, -4.19312328e-01, -8.60743165e-01,\n",
              "         -3.03077161e-01, -4.20868248e-01, -8.85803342e-01,\n",
              "         -8.03128302e-01, -7.13975251e-01,  4.61952239e-02,\n",
              "         -3.56415957e-02, -4.14991558e-01, -4.68070924e-01,\n",
              "         -2.86757380e-01, -1.81800336e-01, -2.16798067e-01,\n",
              "         -3.65595311e-01, -3.15653980e-01, -2.20632270e-01,\n",
              "         -5.98914325e-01, -3.13881636e-01, -1.24440789e-01,\n",
              "         -5.27425170e-01, -5.09712160e-01, -8.48125696e-01,\n",
              "         -2.06711739e-01, -1.50961369e-01, -3.25924188e-01,\n",
              "         -3.31691593e-01, -3.61708313e-01, -4.44436997e-01,\n",
              "         -2.51620436e+00, -1.20257087e-01, -8.12720060e-01,\n",
              "         -1.27712095e+00],\n",
              "        [-6.21698022e-01, -5.70892155e-01, -6.98850274e-01,\n",
              "         -1.97315753e-01, -1.40988544e-01, -4.99531150e-01,\n",
              "         -3.70235592e-01, -2.81973556e-03, -5.98382175e-01,\n",
              "         -3.26511145e-01, -3.51683348e-01, -1.26020181e+00,\n",
              "         -5.30080259e-01, -8.45972538e-01, -1.11491248e-01,\n",
              "         -6.60775602e-01, -5.37964940e-01, -4.78947699e-01,\n",
              "         -5.75402260e-01, -3.43416125e-01, -3.83983731e-01,\n",
              "         -7.87702858e-01, -1.08554661e-02, -7.93293059e-01,\n",
              "         -7.08139062e-01, -5.43697119e-01, -4.97913629e-01,\n",
              "         -6.74093127e-01, -9.28404555e-02, -3.28152090e-01,\n",
              "         -3.35029036e-01, -7.04950094e-01, -2.67603517e-01,\n",
              "         -8.29912663e-01, -3.48940194e-01, -3.19531024e-01,\n",
              "         -7.03809500e-01, -6.48323834e-01, -6.99973583e-01,\n",
              "         -4.31189388e-02, -3.20639312e-02, -9.62360650e-02,\n",
              "         -8.73185217e-01, -5.65789819e-01, -5.98016500e-01,\n",
              "         -2.42370248e-01, -1.50642723e-01, -4.88238186e-02,\n",
              "         -5.38260043e-01, -5.53631365e-01, -5.53319812e-01,\n",
              "         -6.78190053e-01, -5.57826698e-01, -1.03993821e+00,\n",
              "         -3.08066726e-01, -1.40187383e-01, -7.59067357e-01,\n",
              "         -5.43783665e-01, -6.74995422e-01, -6.66266918e-01,\n",
              "         -1.79708135e+00, -1.93748522e+00, -5.99184573e-01,\n",
              "         -5.99045992e-01]], dtype=float32)>,\n",
              " <tf.Variable 'dense_3/bias:0' shape=(64,) dtype=float32, numpy=\n",
              " array([-0.27423334, -0.5162288 , -0.35212874, -0.33340362, -0.1309499 ,\n",
              "        -0.26560706,  0.5483491 , -0.4879453 , -0.7020495 ,  0.51198125,\n",
              "         0.6193729 , -2.0964477 , -0.6005487 , -0.2650359 ,  0.        ,\n",
              "        -0.614146  , -0.11108766, -0.12817964, -0.33681932,  0.27178508,\n",
              "        -0.5816706 , -0.3533211 , -0.5131054 , -0.60054994, -0.63286084,\n",
              "        -0.2580771 , -0.60055417, -0.5507551 , -0.24921836,  0.44246352,\n",
              "        -0.62034035, -0.6634442 , -0.60055256, -0.3280699 , -0.555543  ,\n",
              "        -0.60055506, -0.60055506, -0.582854  , -0.21160923, -0.07787242,\n",
              "        -0.1537076 , -0.60055196, -0.25969708, -0.21616215, -0.44928133,\n",
              "         0.23089772, -0.23127164, -0.07758449,  0.59975296, -0.5171302 ,\n",
              "        -0.32740167, -0.6005551 ,  1.828441  ,  2.303514  , -0.24064234,\n",
              "        -0.1821598 , -0.5792014 , -0.6005547 , -0.20080619, -0.60055447,\n",
              "        -1.3629819 , -0.32008794, -0.60055184,  0.06628646], dtype=float32)>,\n",
              " <tf.Variable 'dense_4/kernel:0' shape=(64, 32) dtype=float32, numpy=\n",
              " array([[-0.7442206 , -0.22058505, -0.41281494, ...,  0.05404085,\n",
              "         -0.30550778, -0.11520189],\n",
              "        [-0.79293305, -0.8171732 , -0.17439055, ...,  0.24140859,\n",
              "         -0.33196846, -0.20969637],\n",
              "        [-0.41677395, -0.74593204, -0.47438893, ..., -0.0446372 ,\n",
              "          0.03881766, -0.6355999 ],\n",
              "        ...,\n",
              "        [-0.67331904, -0.5566693 , -0.45269808, ..., -0.10799885,\n",
              "         -0.40780464, -0.3707578 ],\n",
              "        [-0.53222126, -0.81364226,  0.02327096, ...,  0.11593109,\n",
              "          0.58508784,  0.5448439 ],\n",
              "        [-0.77593696, -0.47945797, -0.03373915, ...,  0.10737538,\n",
              "          0.79169136, -0.11556029]], dtype=float32)>,\n",
              " <tf.Variable 'dense_4/bias:0' shape=(32,) dtype=float32, numpy=\n",
              " array([-6.0055512e-01, -6.0055447e-01, -5.5588812e-01, -7.2785944e-01,\n",
              "        -9.2889234e-02, -1.1499664e-02, -5.8876671e-04, -1.2234557e-01,\n",
              "        -1.5886949e-01,  7.9625428e-01, -6.0055512e-01, -6.0055518e-01,\n",
              "        -2.7102396e-01, -1.5421416e-01, -1.8477401e-01, -6.0055512e-01,\n",
              "        -5.0844282e-01, -1.3904761e-02, -1.6052252e-02, -6.0055447e-01,\n",
              "        -5.1614499e-01, -4.4185114e-01, -7.7107735e-02, -1.2300951e-01,\n",
              "        -3.5912020e+00, -6.0055512e-01, -6.0055500e-01, -6.0055512e-01,\n",
              "        -5.5587029e-01, -1.4058043e+00,  1.0679783e+01, -3.2298940e-01],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_5/kernel:0' shape=(32, 1) dtype=float32, numpy=\n",
              " array([[ 2.3494589e-01],\n",
              "        [ 2.7881724e-01],\n",
              "        [ 3.1135046e-01],\n",
              "        [ 3.1249291e-01],\n",
              "        [ 7.9635039e-02],\n",
              "        [ 5.8710719e-03],\n",
              "        [ 1.1891224e-04],\n",
              "        [-1.7753035e-01],\n",
              "        [-6.7059040e-02],\n",
              "        [ 2.6187000e-01],\n",
              "        [ 3.0726260e-01],\n",
              "        [ 1.8067636e-01],\n",
              "        [-2.2326036e-01],\n",
              "        [-1.9342822e-01],\n",
              "        [-1.5708320e-01],\n",
              "        [ 4.3826923e-01],\n",
              "        [-1.4843087e-01],\n",
              "        [ 2.8185360e-03],\n",
              "        [-1.3468809e-01],\n",
              "        [ 1.9708107e-01],\n",
              "        [ 2.5047293e-01],\n",
              "        [ 5.2992594e-03],\n",
              "        [-1.7320167e-01],\n",
              "        [-1.6400099e-01],\n",
              "        [ 4.0070334e-01],\n",
              "        [ 4.3249318e-01],\n",
              "        [ 5.3080183e-01],\n",
              "        [ 2.3426922e-01],\n",
              "        [ 7.7082348e-01],\n",
              "        [ 1.0502276e+00],\n",
              "        [ 2.2102249e+00],\n",
              "        [-4.6942240e-01]], dtype=float32)>,\n",
              " <tf.Variable 'dense_5/bias:0' shape=(1,) dtype=float32, numpy=array([23.837023], dtype=float32)>]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjuHLl6esYkT",
        "outputId": "ead0ed5f-4e41-45e5-ad69-d4804055621c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[47.65026],\n",
              "       [47.65026],\n",
              "       [47.65026],\n",
              "       ...,\n",
              "       [47.65026],\n",
              "       [47.65026],\n",
              "       [47.65026]], dtype=float32)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "BLqEiXPIs84b"
      },
      "outputs": [],
      "source": [
        "jsonfile=model.to_json()\n",
        "with open (\"model.json\",\"w\") as f:\n",
        "  f.write(jsonfile)\n",
        "\n",
        "model.save(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(64, activation='relu', input_dim=x.shape[1]))\n",
        "model2.add(Dense(32, activation='relu'))\n",
        "model2.add(Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "296/296 [==============================] - 1s 3ms/step - loss: 1073.5278\n",
            "Epoch 2/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 226.2665\n",
            "Epoch 3/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 215.9386\n",
            "Epoch 4/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 212.0518\n",
            "Epoch 5/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 210.0043\n",
            "Epoch 6/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 208.8994\n",
            "Epoch 7/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 208.0073\n",
            "Epoch 8/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 206.9519\n",
            "Epoch 9/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 206.5444\n",
            "Epoch 10/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 205.9798\n",
            "Epoch 11/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 205.3939\n",
            "Epoch 12/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 205.3592\n",
            "Epoch 13/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 204.5120\n",
            "Epoch 14/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 203.9293\n",
            "Epoch 15/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 203.1004\n",
            "Epoch 16/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 202.5656\n",
            "Epoch 17/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 201.8857\n",
            "Epoch 18/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 201.8318\n",
            "Epoch 19/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 200.4341\n",
            "Epoch 20/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 200.5569\n",
            "Epoch 21/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 199.6769\n",
            "Epoch 22/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 199.6438\n",
            "Epoch 23/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 198.9943\n",
            "Epoch 24/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 199.1163\n",
            "Epoch 25/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 198.6850\n",
            "Epoch 26/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 198.0649\n",
            "Epoch 27/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 198.1781\n",
            "Epoch 28/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.6280\n",
            "Epoch 29/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.6200\n",
            "Epoch 30/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.8112\n",
            "Epoch 31/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.2762\n",
            "Epoch 32/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.5541\n",
            "Epoch 33/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.3409\n",
            "Epoch 34/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.0431\n",
            "Epoch 35/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.1474\n",
            "Epoch 36/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.9927\n",
            "Epoch 37/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.7320\n",
            "Epoch 38/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.9968\n",
            "Epoch 39/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.8830\n",
            "Epoch 40/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.9955\n",
            "Epoch 41/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.5559\n",
            "Epoch 42/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.1474\n",
            "Epoch 43/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.5058\n",
            "Epoch 44/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 197.0166\n",
            "Epoch 45/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.2770\n",
            "Epoch 46/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.4185\n",
            "Epoch 47/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.0901\n",
            "Epoch 48/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.1504\n",
            "Epoch 49/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.0135\n",
            "Epoch 50/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.0198\n",
            "Epoch 51/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.9997\n",
            "Epoch 52/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.3006\n",
            "Epoch 53/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.0320\n",
            "Epoch 54/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.8527\n",
            "Epoch 55/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.9250\n",
            "Epoch 56/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.9376\n",
            "Epoch 57/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.6826\n",
            "Epoch 58/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.4916\n",
            "Epoch 59/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.6080\n",
            "Epoch 60/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.1549\n",
            "Epoch 61/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.5978\n",
            "Epoch 62/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.8601\n",
            "Epoch 63/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.2664\n",
            "Epoch 64/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.4728\n",
            "Epoch 65/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.5824\n",
            "Epoch 66/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.9588\n",
            "Epoch 67/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.5695\n",
            "Epoch 68/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.2546\n",
            "Epoch 69/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.5592\n",
            "Epoch 70/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.3907\n",
            "Epoch 71/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.1656\n",
            "Epoch 72/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.2100\n",
            "Epoch 73/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 196.0015\n",
            "Epoch 74/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.2909\n",
            "Epoch 75/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.5400\n",
            "Epoch 76/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.1351\n",
            "Epoch 77/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.1721\n",
            "Epoch 78/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.1849\n",
            "Epoch 79/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.2516\n",
            "Epoch 80/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.0139\n",
            "Epoch 81/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.1200\n",
            "Epoch 82/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.3484\n",
            "Epoch 83/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.9949\n",
            "Epoch 84/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.0357\n",
            "Epoch 85/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.7303\n",
            "Epoch 86/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.2844\n",
            "Epoch 87/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.0932\n",
            "Epoch 88/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.9219\n",
            "Epoch 89/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.6178\n",
            "Epoch 90/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.0102\n",
            "Epoch 91/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.2091\n",
            "Epoch 92/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.7538\n",
            "Epoch 93/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.4601\n",
            "Epoch 94/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.7978\n",
            "Epoch 95/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.6446\n",
            "Epoch 96/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 195.4450\n",
            "Epoch 97/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.7459\n",
            "Epoch 98/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.6472\n",
            "Epoch 99/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.4594\n",
            "Epoch 100/100\n",
            "296/296 [==============================] - 1s 2ms/step - loss: 194.4660\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1c8a27fe828>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model2.fit(X_train, y_train, epochs=100, batch_size=64, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model2.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): 191.77556935765304\n",
            "R-squared (R2) Score: 0.09713849341611613\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R2) Score:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.save('scaled_model_191MSE.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sex                       2.0\n",
              "highest_qualification     9.0\n",
              "rural                     2.0\n",
              "disability_status         7.0\n",
              "is_water_filter           2.0\n",
              "chew                      7.0\n",
              "smoke                     4.0\n",
              "alcohol                   4.0\n",
              "treatment_source         99.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
